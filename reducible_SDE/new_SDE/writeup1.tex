\documentclass[12pt]{article}

\usepackage{amsmath}
\usepackage[margin=1in]{geometry}

\begin{document}

\section{Multiscale SDEs}

Consider the SDEs
\begin{eqnarray}
dx &=& adt + dW_1\\
dy &=& -\frac{y}{\epsilon} dt + \frac{1}{\sqrt{\epsilon}} dW_2
\end{eqnarray}

So $y$ is a fast noise whose equilibrium measure is bounded and $\mathcal{O}(1)$

Let $y = \frac{z}{\sqrt{\epsilon}}$. Then
\begin{eqnarray}
dx &=& adt + dW_1\\
dz &=& -\frac{z}{\epsilon} dt +  dW_2
\end{eqnarray}

Therefore, now $z$ is a stochastic variable whose diffusion is unity, and whose equilibrium measure is $\mathcal{O}(\epsilon)$. 
%
Therefore, when $\epsilon \ll 1$, we have that $z \ll x$, and so we will recover $x$ only.

This falls into a more general form of SDE
\begin{equation}
dx_i = f(X) dt + dW_i
\end{equation}
and we will let $X = \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix}$

\section{Covariance Estimation}

Given $X$ governed by the above SDE, we can sample ``bursts'' around a point $X_0$ in order to estimate the covariance. 

These clouds will be distributed 

\begin{equation}
X \sim \mathcal{N}\left( X_0, \delta t I \right)
\end{equation}

Then
$$\int_{-\infty}^{\infty} d\mu(X) = \begin{bmatrix} 1 \\ \vdots \\ 1\end{bmatrix}$$
$$\int_{-\infty}^{\infty} X d\mu(X) = X_0$$
$$\int_{-\infty}^{\infty} X X^T d\mu(X) - \left( \int_{-\infty}^{\infty} X d\mu(X) \right) \left( \int_{-\infty}^{\infty} X d\mu(X) \right)^T = \delta t I$$


We now consider a function $\mathbf{f}(X)$.
%
By Taylor expansion around $X=X_0$,
\begin{eqnarray}
f^i(X) &=& 
f^i(X_0) 
+ \sum_k f^i_k(X_0)  (X^k-X^k_0) 
+\frac{1}{2} \sum_{k,l}  f^i_{kl} (X_0) (X^k-X_0^k) (X^l-X_0^l) \\
&& + \frac{1}{6} \sum_{k,l,m} f^i_{klm} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m) \\
&& + \frac{1}{24} \sum_{k,l,m,n} f^i_{klmn} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m) (X^n-X_0^n)
+ \mathcal{O}\left( \| X- X_0 \|^5 \right)
\end{eqnarray}

We can then approximate the first- and second-order moments 
\begin{eqnarray}
&&\int_{-\infty}^{\infty} f^i(X) d\mu(X) \\
&= & \int_{-\infty}^{\infty} \left[ f^i(X_0) + \sum_k f^i_k(X_0) (X^k-X_0^k)  + \frac{1}{2} \sum_{k,l} f^i_{kl}(X_0) (X^k-X_0^k) (X^l-X_0^l)  \right. \\
&& + \frac{1}{6} \sum_{k,l,m} f^i_{klm} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m) \\
&& \left. + \frac{1}{24} \sum_{k,l,m,n} f^i_{klmn} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m) (X^n-X_0^n)
+ \mathcal{O}\left( \| X- X_0 \|^5 \right) \right] d\mu(X) \\
&=& f^i(X_0) + \frac{1}{2} \sum_k f^i_{kk}(X_0) \delta t + \frac{\delta t^2}{8} \sum_{k} f^i_{kkkk} (X_0) + \mathcal{O} (\delta t^3 )
\end{eqnarray}

\begin{eqnarray}
&&\int_{-\infty}^{\infty} f^i(X) f^j(X) d\mu(X) \\
&= &
\int_{-\infty}^{\infty} \left[ f^i(X_0) + \sum_k f^i_k(X_0) (X^k-X_0^k)  + \frac{1}{2} \sum_{k,l} f^i_{kl}(X_0) (X^k-X_0^k) (X^l-X_0^l) \right. \\
&&  + \frac{1}{6} \sum_{k,l,m} f^i_{klm} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m) \\
&& \left. + \frac{1}{24} \sum_{k,l,m,n} f^i_{klmn} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m) (X^n-X_0^n)
+ \mathcal{O}\left( \| X- X_0 \|^5 \right) \right]  \\
&& \left[ f^j(X_0) + \sum_k f^j_k(X_0) (X^k-X_0^k)  + \frac{1}{2} \sum_{k,l} f^j_{kl}(X_0) (X^k-X_0^k) (X^l-X_0^l)  \right. \\
&&  + \frac{1}{6} \sum_{k,l,m} f^j_{klm} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m)  \\
&&  \left. + \frac{1}{24} \sum_{k,l,m,n} f^j_{klmn} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m) (X^n-X_0^n)
+ \mathcal{O}\left( \| X- X_0 \|^5 \right) \right]  d\mu(X) 
\end{eqnarray}

\begin{eqnarray}
&=& \int_{-\infty}^{\infty} \left[ 
f^i(X_0) f^j(X_0) \right. \\
&&+ f^i(X_0) \sum_k f^j_k(X_0) (X^k-X_0^k) 
+ f^j(X_0) \sum_k f^i_k(X_0) (X^k-X_0^k) \\
&& + \left(  \sum_k f^i_k(X_0) (X^k-X_0^k)  \right) \left(  \sum_k f^j_k(X_0) (X^k-X_0^k)  \right) \\
&& \left. + \frac{f^i(X_0)}{2} \sum_{k,l} f^j_{kl}(X_0) (X^k-X_0^k) (X^l-X_0^l) 
+ \frac{f^j(X_0)}{2} \sum_{k,l} f^i_{kl}(X_0) (X^k-X_0^k) (X^l-X_0^l)  \right. \\
&& + \frac{f^i(X_0)}{6} \sum_{k,l,m} f^j_{klm} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m) \\
&& + \frac{f^j(X_0)}{6} \sum_{k,l,m} f^i_{klm} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m) \\
&& + \left(\sum_k f^i_k(X_0) (X^k-X_0^k) \right) \left( \frac{f^j(X_0)}{2} \sum_{k,l} f^j_{kl}(X_0) (X^k-X_0^k) (X^l-X_0^l)  \right) \\
&& + \left(\sum_k f^j_k(X_0) (X^k-X_0^k) \right) \left( \frac{f^i(X_0)}{2} \sum_{k,l} f^j_{kl}(X_0) (X^k-X_0^k) (X^l-X_0^l)  \right)\\
&&+ \frac{f^i(X_0) }{24} \sum_{k,l,m,n} f^j_{klmn} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m) (X^n-X_0^n) \\
&& + \frac{f^j(X_0) }{24} \sum_{k,l,m,n} f^i_{klmn} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m) (X^n-X_0^n) \\
&& + \left( \sum_k f^i_k(X_0) (X^k-X_0^k) \right) \left( \frac{1}{6} \sum_{k,l,m} f^j_{klm} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m)  \right) \\
&& + \left( \sum_k f^j_k(X_0) (X^k-X_0^k) \right) \left( \frac{1}{6} \sum_{k,l,m} f^i_{klm} (X_0) (X^k-X_0^k) (X^l-X_0^l) (X^m-X_0^m)  \right) \\
&&+ \left( \frac{1}{2} \sum_{k,l} f^i_{kl}(X_0) (X^k-X_0^k) (X^l-X_0^l)  \right) \left( \frac{1}{2} \sum_{k,l} f^j_{kl}(X_0) (X^k-X_0^k) (X^l-X_0^l)  \right) \\
&&\left. + \mathcal{O}\left( \| X- X_0 \|^5 \right) \right] d\mu(X) \\
 \end{eqnarray}
 
 \begin{eqnarray}
 &=& 
f^i(X_0) f^j(X_0) \\
&& + \delta t \sum_k f^i_k(X_0)  f^j_k(X_0) \\
&&  + \frac{f^i(X_0) \delta t}{2} \sum_{k} f^j_{kk}(X_0)
+ \frac{f^j(X_0) \delta t}{2} \sum_{k} f^i_{kk}(X_0)  \\
&&+ \frac{f^i(X_0) \delta t^2}{8} \sum_{k} f^j_{kkkk} (X_0) \\
&& + \frac{f^j(X_0) \delta t^2}{8} \sum_{k} f^i_{kkkk} (X_0)\\
&& + \frac{\delta t^2}{2} \sum_k f^i_k(X_0) f^j_{kkk} (X_0)  \\
&& + \frac{\delta t^2}{2}  f^i_{kkk} (X_0) \sum_k f^j_k(X_0) \\
&&+  \frac{3  \delta t^2}{4} \sum_{k} f^i_{kk}(X_0) f^j_{kk}(X_0) \\
&& + \mathcal{O}\left( \delta t^3 \right) 
\end{eqnarray}

We then write
\begin{eqnarray}
&& \hat{C}^{ij} = \\ 
&& \int_{-\infty}^{\infty} f^i(X) f^j(X) d\mu(X) - \left(\int_{-\infty}^{\infty} f^i(X) d\mu(X) \right) \left(\int_{-\infty}^{\infty} f^j(X) d\mu(X) \right) \\
&=& \left( f^i(X_0) f^j(X_0) 
 + \delta t \sum_k f^i_k(X_0)  f^j_k(X_0) \right.   \\
&&  + \frac{f^i(X_0) \delta t}{2} \sum_{k} f^j_{kk}(X_0)
+ \frac{f^j(X_0) \delta t}{2} \sum_{k} f^i_{kk}(X_0)  \\
&&+ \frac{f^i(X_0) \delta t^2}{8} \sum_{k} f^j_{kkkk} (X_0) 
+ \frac{f^j(X_0) \delta t^2}{8} \sum_{k} f^i_{kkkk} (X_0)\\
&& + \frac{\delta t^2}{2} \sum_k f^i_k(X_0) f^j_{kkk} (X_0)  
 + \frac{\delta t^2}{2} \sum_k f^i_{kkk} (X_0) f^j_k(X_0) \\
&&+  \frac{3  \delta t^2}{4} \sum_{k} f^i_{kk}(X_0) f^j_{kk}(X_0) 
 \left.+ \mathcal{O}\left( \delta t^3 \right) \right) \\
&&- \left( f^i(X_0) + \frac{1}{2} \sum_k f^i_{kk}(X_0) \delta t + \frac{\delta t^2}{8} \sum_{k} f^i_{kkkk} (X_0) + \mathcal{O} (\delta t^3 ) \right) \\
&&\left( f^j(X_0) + \frac{1}{2} \sum_k f^j_{kk}(X_0) \delta t + \frac{\delta t^2}{8} \sum_{k} f^j_{kkkk} (X_0) + \mathcal{O} (\delta t^3 ) \right) \\
&=&
\delta t \sum_k f^i_k(X_0)  f^j_k(X_0) 
+ \frac{\delta t^2}{2} \sum_k f^i_k(X_0) f^j_{kkk} (X_0)  
 + \frac{\delta t^2}{2} \sum_k f^i_{kkk} (X_0) f^j_k(X_0) \\
&&+  \frac{3 \delta t^2}{4} \sum_{k} f^i_{kk}(X_0) f^j_{kk}(X_0) 
- \frac{\delta t^2}{4} \left( \sum_k f^i_{kk}(X_0) \right) \left( \sum_k f^j_{kk}(X_0) \right) 
 + \mathcal{O}\left( \delta t^3 \right) \\
\end{eqnarray}

%&=& \left( f^i(X_0) f^j(X_0) + \delta t \sum_k f_k^i(X_0) f_k^j(X_0) \right. \\
%&& \left. +  \frac{f^i(X_0) \delta t}{2} \sum_k f^j_{kk}(X_0) + \frac{f^j(X_0) \delta t}{2} \sum_k f^i_{kk}(X_0) \right) \\
%&& - \left(f^i(X_0) + \frac{ \delta t}{2} \sum_k f^i_{kk}(X_0) \right)
%\left(f^j(X_0) + \frac{ \delta t}{2} \sum_k f^j_{kk}(X_0)  \right) \\
%&=& \delta t \sum_k f_k^i(X_0) f_k^j(X_0) - \frac{\delta t^2}{4} \left( \sum_k f^i_{kk}(X_0) \right) \left( \sum_k f^j_{kk}(X_0) \right)
%\end{eqnarray}

Let 
\begin{equation}
J_1(X_0) = \begin{bmatrix}
f_1^1 & f_2^1 & \dots & f_n^1 \\
\vdots & \vdots & \cdots & \vdots \\
f_1^m & f_2^m & \dots & f_n^m
\end{bmatrix}
\end{equation}

\begin{equation}
J_2(X_0) = \begin{bmatrix}
f_{11}^1 & f_{22}^1 & \dots & f_{nn}^1 \\
\vdots & \vdots & \cdots & \vdots \\
f_{11}^m & f_{22}^m & \dots & f_{nn}^m
\end{bmatrix}
\end{equation}

\begin{equation}
J_3(X_0) = \begin{bmatrix}
f_{111}^1 & f_{222}^1 & \dots & f_{nnn}^1 \\
\vdots & \vdots & \cdots & \vdots \\
f_{111}^m & f_{222}^m & \dots & f_{nnn}^m
\end{bmatrix}
\end{equation}

Then
\begin{equation}
C(X_0) = \delta t J_1 J_1^T 
+ \frac{\delta t}{2} \left( J_1 J_3^T + J_3 J_1^T \right) 
+ \frac{3 \delta t}{4} J_2 J_2^T 
-\frac{\delta t^2}{4} J_2 1 1^T J_2^T
+ \mathcal{O} (\delta t^3)
\end{equation}
 
 STOPPED HERE!!
 
In this equation, we see what we expect (a linear function of the variance, due to the gradient of $f$) and a second term arising from the curvature of $f$.
%
The importance of this second term increases as the curvature increases, and when the variance of the underlying process increases. 

 By the Sherman-Morrison formula,
 \begin{eqnarray}
 C^{-1}(X_0) &=&  
 \left(\delta t J J^T \right)^{-1} - \frac{ \left(\delta t J J^T \right)^{-1} \frac{\delta t^2}{4} H H^T \left(\delta t J J^T \right)^{-1} }{1+ \frac{\delta t^2}{4} H^T \left(\delta t J J^T \right)^{-1} H} \\
 &=& \frac{1}{\delta t} \left(J J^T \right)^{-1} \left[ I - \delta t \frac{ H H^T \left(J J^T \right)^{-1} }{4+ \delta t H^T \left( J J^T \right)^{-1} H } \right]  \\
 &=& \frac{1}{\delta t} \left(J J^T \right)^{-1} \left( I - A  \right)
 \end{eqnarray}
where $A = \delta t \frac{ H H^T \left(J J^T \right)^{-1} }{4+ \delta t H^T \left( J J^T \right)^{-1} H }$

For the specific case of our fast-slow SDEs:
$$f^1(X) = X(1)$$
$$f^2(X) = \frac{X(2)}{\sqrt{\epsilon}}$$
and so the covariance estimation is exact (provided we do not see the drift).

When we apply a nonlinear function, i.e., 
$$f^1(X) = \frac{X(2)}{\sqrt{\epsilon}} \cos \left(X(1)+\frac{X(2)}{\sqrt{\epsilon}} \right)$$
$$f^2(X) = \frac{X(2)}{\sqrt{\epsilon}} \sin \left(X(1)+\frac{X(2)}{\sqrt{\epsilon}} \right)$$

\begin{eqnarray}
H_{11}^1 &=& 
-\frac{X(2)}{\sqrt{\epsilon}} \cos \left(X(1)+\frac{X(2)}{\sqrt{\epsilon}} \right) \\
H_{22}^1 &=&
-\frac{X(2)}{\epsilon^{3/2}} \cos \left(X(1)+\frac{X(2)}{\sqrt{\epsilon}} \right) - \left( \frac{1}{\epsilon} + \frac{1}{\epsilon^{3/2}} \right) \sin \left(X(1)+\frac{X(2)}{\sqrt{\epsilon}} \right) 
\end{eqnarray}

TODO: finish nonlinear case/example


\section{Mahalanobis Distance}


We now approximate the distances $\| X_2 - X_1 \|$.
%
Let $g = f^{-1}$, and let $Y_1 = f(X_1)$, and $Y_2 = f(X_2)$
%
Then
%
\begin{eqnarray}
X_2^i &=& X_1^i + \sum_j g_j^i (Y_1) (Y^j_2 - Y^j_1 ) 
+ \frac{1}{2} \sum_{kl}  g^i_{kl} (Y_1) (Y^k_2 - Y^k_1)(Y^l_2 - Y^l_1) \\
&&+ \frac{1}{6} \sum_{klm}  g^i_{klm} (Y_1) (Y^k_2 - Y^k_1)(Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) 
+ \mathcal{O}( \|Y_2 - Y_1\|^4 )
\end{eqnarray}

Then computing the distance
\begin{eqnarray}
&&\| X_2 - X_1 \|^2 \\
&=&  \sum_i (X_2^i - X_1^i)^2 \\
&=& \sum_i  \left( \sum_j g_j^i (Y_1) (Y^j_2 - Y^j_1 )  \right.
+ \frac{1}{2} \sum_{kl}  g^i_{kl} (Y_1) (Y^k_2 - Y^k_1)(Y^l_2 - Y^l_1) \\
&&+ \left.  \frac{1}{6} \sum_{klm}  g^i_{klm} (Y_1) (Y^k_2 - Y^k_1)(Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) 
 + \mathcal{O}( \|Y_2 - Y_1\|^4 ) \right)^2 \\
&=& \sum_{ijk} g_j^i (Y_1) g_k^i (Y_1) (Y^j_2 - Y^j_1 ) (Y^k_2 - Y^k_1 ) \\
&& + \sum_{ijkl} g_j^i (Y_1) g^i_{kl} (Y_1) (Y^j_2 - Y^j_1 )  (Y^k_2 - Y^k_1)(Y^l_2 - Y^l_1) \\
&& + \frac{1}{4} \sum_{ijklm}  g^i_{jk} (Y_1) g^i_{lm} (Y_1) (Y^j_2 - Y^j_1) (Y^k_2 - Y^k_1) (Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) \\
&& + \frac{1}{3} \sum_{ijklm}  g^i_{j} (Y_1) g^i_{klm} (Y_1) (Y^j_2 - Y^j_1) (Y^k_2 - Y^k_1) (Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) \\
&& + \mathcal{O} (\|Y_1 - Y_2 \|^5 )
\end{eqnarray}

Expanding around $X_2$ yields
\begin{eqnarray}
&&\| X_2 - X_1 \|^2 \\
&=&  \sum_i (X_2^i - X_1^i)^2 \\
&=& \sum_{ijk} g_j^i (Y_2) g_k^i (Y_2) (Y^j_2 - Y^j_1 ) (Y^k_2 - Y^k_1 ) \\
&& - \sum_{ijkl} g_j^i (Y_2) g^i_{kl} (Y_2) (Y^j_2 - Y^j_1 )  (Y^k_2 - Y^k_1)(Y^l_2 - Y^l_1) \\
&& + \frac{1}{4} \sum_{ijklm}  g^i_{jk} (Y_2) g^i_{lm} (Y_2) (Y^j_2 - Y^j_1) (Y^k_2 - Y^k_1) (Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) \\
&& + \frac{1}{3} \sum_{ijklm}  g^i_{j} (Y_2) g^i_{klm} (Y_2) (Y^j_2 - Y^j_1) (Y^k_2 - Y^k_1) (Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) \\
&& + \mathcal{O} (\|Y_1 - Y_2 \|^5 )
\end{eqnarray}

Averaging the two expansions yields
\begin{eqnarray}
&&\| X_2 - X_1 \|^2 \\
&=&  \sum_i (X_2^i - X_1^i)^2 \\
&=& \frac{1}{2} \sum_{ijk} \left( g_j^i (Y_1) g_k^i (Y_1) + g_j^i (Y_2) g_k^i (Y_2) \right) (Y^j_2 - Y^j_1 ) (Y^k_2 - Y^k_1 ) \\
&& + \frac{1}{2} \sum_{ijkl} \left( g_j^i (Y_1) g^i_{kl} (Y_1) - g_j^i (Y_2) g^i_{kl} (Y_2) \right) (Y^j_2 - Y^j_1 )  (Y^k_2 - Y^k_1)(Y^l_2 - Y^l_1) \\
&& + \frac{1}{8} \sum_{ijklm}  \left( g^i_{jk} (Y_1) g^i_{lm} (Y_1) + g^i_{jk} (Y_2) g^i_{lm} (Y_2)  \right) (Y^j_2 - Y^j_1) (Y^k_2 - Y^k_1) (Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) \\
&& + \frac{1}{6} \sum_{ijklm}  \left( g^i_{j} (Y_1) g^i_{klm} (Y_1) + g^i_{j} (Y_2) g^i_{klm} (Y_2)  \right)(Y^j_2 - Y^j_1) (Y^k_2 - Y^k_1) (Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) \\
&& + \mathcal{O} (\|Y_1 - Y_2 \|^6 ) \\
&=& \frac{1}{2} (Y_2 - Y_1 )^T ((J J^T)^{-1} (Y_1) + (J J^T)^{-1}(Y_2)) (Y_2 - Y_1 ) \\
&& + \frac{1}{2} \sum_{ijkl} \left( g_j^i (Y_1) g^i_{kl} (Y_1) - g_j^i (Y_2) g^i_{kl} (Y_2) \right) (Y^j_2 - Y^j_1 )  (Y^k_2 - Y^k_1)(Y^l_2 - Y^l_1) \\
&& + \frac{1}{8} \sum_{ijklm}  \left( g^i_{jk} (Y_1) g^i_{lm} (Y_1) + g^i_{jk} (Y_2) g^i_{lm} (Y_2)  \right) (Y^j_2 - Y^j_1) (Y^k_2 - Y^k_1) (Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) \\
&& + \frac{1}{6} \sum_{ijklm}  \left( g^i_{j} (Y_1) g^i_{klm} (Y_1) + g^i_{j} (Y_2) g^i_{klm} (Y_2)  \right)(Y^j_2 - Y^j_1) (Y^k_2 - Y^k_1) (Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) \\
&& + \mathcal{O} (\|Y_1 - Y_2 \|^6 ) 
\end{eqnarray}

If we substitute our expression for our {\em estimate} of $C^{-1} = (J J^T) ^{-1}$, we obtain
\begin{eqnarray}
&&\| X_2 - X_1 \|^2 \\
&\approx&  \frac{1}{2} (Y_2 - Y_1 )^T ((J J^T)^{-1} (Y_1) (I-A(Y_1))+ (J J^T)^{-1}(Y_2) (I-A(Y_2))) (Y_2 - Y_1 ) \\
&& + \frac{1}{2} \sum_{ijkl} \left( g_j^i (Y_1) g^i_{kl} (Y_1) - g_j^i (Y_2) g^i_{kl} (Y_2) \right) (Y^j_2 - Y^j_1 )  (Y^k_2 - Y^k_1)(Y^l_2 - Y^l_1) \\
&& + \frac{1}{8} \sum_{ijklm}  \left( g^i_{jk} (Y_1) g^i_{lm} (Y_1) + g^i_{jk} (Y_2) g^i_{lm} (Y_2)  \right) (Y^j_2 - Y^j_1) (Y^k_2 - Y^k_1) (Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) \\
&& + \frac{1}{6} \sum_{ijklm}  \left( g^i_{j} (Y_1) g^i_{klm} (Y_1) + g^i_{j} (Y_2) g^i_{klm} (Y_2)  \right)(Y^j_2 - Y^j_1) (Y^k_2 - Y^k_1) (Y^l_2 - Y^l_1) (Y^m_2 - Y^m_1) \\
&& + \mathcal{O} (\|Y_1 - Y_2 \|^6 ) 
\end{eqnarray}

\begin{itemize}
\item Make 2D with fast-slow
\item Use $dt$ rather than $\sigma$ for variance
\item Add into Mahalanobis distance approximation
\item Add second order term in Mahalanobis distance
\end{itemize}
\end{document}